{
  "cells": [
    {
      "metadata": {
        "_uuid": "e28c6108cb4be55dc80243e710eafb9a96ceb2ba",
        "_cell_guid": "484a9abd-cec1-4d1e-809a-03f3c007cb2d"
      },
      "cell_type": "markdown",
      "source": "# Packages"
    },
    {
      "metadata": {
        "_uuid": "548a5b07e2a2e658cfe7d5fb32fd6fa1aa8db556",
        "_cell_guid": "95455ca6-b733-443d-9e86-7075ad9fca57",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\nfrom sklearn.cross_validation import train_test_split\n\nimport matplotlib.pyplot as plt\n%matplotlib inline \n\nimport math\nfrom nltk import tokenize\n\nfrom keras.preprocessing.text import Tokenizer, text_to_word_sequence\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils.np_utils import to_categorical\n\nfrom keras.layers import Embedding\nfrom keras.layers import Dense, Input, Flatten\nfrom keras.layers import Conv1D, MaxPooling1D, Embedding, Merge, Dropout, LSTM, GRU, Bidirectional, TimeDistributed\nfrom keras.models import Model\n\nfrom keras import backend as K\nfrom keras.engine.topology import Layer, InputSpec\n\n\nimport tensorflow as tf\nfrom keras.backend.tensorflow_backend import set_session\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nset_session(tf.Session(config=config))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "20de159616fa597450623673dad288c5d0d2b6a8",
        "_cell_guid": "bc2fcf27-495a-4975-b8c9-a7d5865d53d0"
      },
      "cell_type": "markdown",
      "source": "# Data handling"
    },
    {
      "metadata": {
        "_uuid": "b94fe8c27c81a2ee99702ca21868807a2d8f45ee",
        "_cell_guid": "4a69814c-fd42-4971-a860-b1692d45deaa"
      },
      "cell_type": "markdown",
      "source": "## Load data"
    },
    {
      "metadata": {
        "_uuid": "307c2687388ce50634a92995648d9e129c29f3a8",
        "_cell_guid": "9badc05d-8a23-4379-a7d0-3c90cdb4e174",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#LOAD DATA\nprint(\"Loading data...\")\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\ntrain = pd.read_table(\"../input/mercari-price-suggestion-challenge/train.tsv\")\ntest = pd.read_table(\"../input/mercari-price-suggestion-challenge/test.tsv\")\nprint('Data loaded')\nprint(train.shape)\nprint(test.shape)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "47c8fe5402a4573687cb474bc9998ce629169ecb",
        "_cell_guid": "85f62bce-4662-45d8-901f-acb8dbec0305"
      },
      "cell_type": "markdown",
      "source": "## Handle missing values"
    },
    {
      "metadata": {
        "_uuid": "5ce53ca47accc99bc1a913126a720f2b93c2bd7d",
        "_cell_guid": "efe6015d-9e5d-4c7b-806d-791caf0eba6c",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#HANDLE MISSING VALUES\nprint(\"Handling missing values...\")\ndef handle_missing(dataset):\n    dataset.category_name.fillna(value=\"missing\", inplace=True)\n    dataset.brand_name.fillna(value=\"missing\", inplace=True)\n    dataset.item_description.fillna(value=\"missing\", inplace=True)\n    return (dataset)\n\ntrain = handle_missing(train)\ntest = handle_missing(test)\nprint(train.shape)\nprint(test.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d1b3f9d4c1cad61635d9d305b1317a662741467b",
        "_cell_guid": "bea82d4a-0096-4cde-9259-472592f1d439",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train.head(3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9fafbdd3bfd416b8eb44cc785329bf7f410a9a79",
        "_cell_guid": "8e542d42-a0a7-4a0b-8964-cb2aae13a41b"
      },
      "cell_type": "markdown",
      "source": "## Handle categorial features"
    },
    {
      "metadata": {
        "_uuid": "fe73e27863961ea6a06ca7ed4b666b877c6c7814",
        "_cell_guid": "1d66a19b-8ea4-45be-84ea-7a8c16a48682",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#PROCESS CATEGORICAL DATA\nprint(\"Handling categorical variables...\")\nle = LabelEncoder()\n\nle.fit(np.hstack([train.category_name, test.category_name]))\ntrain.category_name = le.transform(train.category_name)\ntest.category_name = le.transform(test.category_name)\n\nle.fit(np.hstack([train.brand_name, test.brand_name]))\ntrain.brand_name = le.transform(train.brand_name)\ntest.brand_name = le.transform(test.brand_name)\ndel le\n\ntrain.head(3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f6a8cbefa263245a27bf4fd55dfc1d516b0d0a2e",
        "_cell_guid": "cd6ef01a-6c9a-47ba-a23a-042ad2a69c05"
      },
      "cell_type": "markdown",
      "source": "## Handle text features"
    },
    {
      "metadata": {
        "_uuid": "b22443174ecd8236dd72b127ff6a23803e04ebc0",
        "_cell_guid": "b0379199-cc1b-4064-aeb8-f23592ea2c88",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#PROCESS TEXT: RAW\nprint(\"Text to seq process...\")\nfrom keras.preprocessing.text import Tokenizer\nraw_text = np.hstack([train.item_description.str.lower(), train.name.str.lower()])\nprint(\"   Transforming text to seq of sentences, which is a sequence of words...\")\nprint(\"   Fitting tokenizer...\")\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(raw_text)\nword_index = tokenizer.word_index\nprint('Total %s unique tokens.' % len(word_index))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "d4a5fe03356eee8118c516306978d52670d71d98",
        "_cell_guid": "e5c4c74c-d048-4065-a386-566f3b65fe59",
        "trusted": false
      },
      "cell_type": "code",
      "source": "\nMAX_SENTS = 5\nMAX_SENT_LENGTH = 25\nMAX_NB_WORDS = 20000\ndef process_hierarichal_text(descriptions_raw):\n    descriptions = []\n    for description in descriptions_raw:\n        \n        #sentences = tokenize.sent_tokenize(description.decode('utf8'))        \n        sentences = tokenize.sent_tokenize(description)\n        \n        '''\n        MAX_SENTS = max(MAX_SENTS, len(sentences))\n        for sent in sentences:\n            MAX_SENT_LENGTH = max(MAX_SENT_LENGTH, len(tok_raw.texts_to_sequences(sent)))\n        '''\n        descriptions.append(sentences)\n    #print('MAX_SENTS = ', MAX_SENTS)\n    #print('MAX_SENT_LENGTH = ', MAX_SENT_LENGTH)\n\n    data = np.zeros((len(descriptions_raw), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n    #n_errs = 0\n    for i, description in enumerate(descriptions):\n        sent_words_indices = tokenizer.texts_to_sequences(description)\n        for j in range(len(sent_words_indices)):\n            if j< MAX_SENTS:\n                for k in range(len(sent_words_indices[j])):\n                    word_idx = sent_words_indices[j][k]\n                    if k < MAX_SENT_LENGTH and word_idx < MAX_NB_WORDS:\n                        data[i,j,k] = word_idx\n                        #print(data[i,j,k])\n                    \n    #print('Total errors=', n_errs)\n    #print(data)\n    return data\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "52953a57f3a4fd2517b02c2b9ddbd6f9b5b4c8d7",
        "_cell_guid": "b378eb41-2dfc-49fd-86a9-b72a7bd7b570",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print('Total %s unique tokens.' % len(word_index))\n\ntrain_seq_item_desc = process_hierarichal_text(train.item_description.str.lower())\ntest_seq_item_desc = process_hierarichal_text(test.item_description.str.lower())\n \ntrain[\"seq_item_description\"] = list(train_seq_item_desc)\ntest[\"seq_item_description\"] = list(test_seq_item_desc)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4d0d3826d8a732d64948962167f2dcdca0ba186a",
        "_cell_guid": "9db24678-ae40-4403-9a68-e76c7f140a97",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train[\"seq_name\"] = tokenizer.texts_to_sequences(train.name.str.lower())\ntest[\"seq_name\"] = tokenizer.texts_to_sequences(test.name.str.lower())\ntrain.head(3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f90d66cc5a09f005bec5fa02ba24bf5565a7f87d",
        "_cell_guid": "de1c02e5-03d4-4a74-a277-1b5b9293e0d3"
      },
      "cell_type": "markdown",
      "source": "### Embeddings"
    },
    {
      "metadata": {
        "_uuid": "d8274e8ad882a8016377127279cb4134a1195190",
        "_cell_guid": "6ea16307-81d7-4da6-85c2-8677e9206817"
      },
      "cell_type": "markdown",
      "source": "### Embeddings size calculations"
    },
    {
      "metadata": {
        "_uuid": "d6d2a33e393c706723ef610e56b146eeb45513dd",
        "_cell_guid": "790d740e-e1af-4ccb-a462-643ffbf61a38",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#SEQUENCES VARIABLES ANALYSIS\nmax_name_seq = np.max([np.max(train.seq_name.apply(lambda x: len(x))), np.max(test.seq_name.apply(lambda x: len(x)))])\nmax_seq_item_description = np.max([np.max(train.seq_item_description.apply(lambda x: len(x)))\n                                   , np.max(test.seq_item_description.apply(lambda x: len(x)))])\nprint(\"max name seq \"+str(max_name_seq))\nprint(\"max item desc seq \"+str(max_seq_item_description))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "b1e8d8d8cc35251b872fabc340c4b644d7b12b6e",
        "_cell_guid": "90c22ad3-2259-4619-bd30-c1620f4436f5",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#EMBEDDINGS MAX VALUE\n#Base on the histograms, we select the next lengths\nMAX_NAME_SEQ = 10\n#MAX_ITEM_DESC_SEQ = 75\nMAX_TEXT = np.max([np.max(train.seq_name.max())\n                   , np.max(test.seq_name.max())])+2\nMAX_CATEGORY = np.max([train.category_name.max(), test.category_name.max()])+1\nMAX_BRAND = np.max([train.brand_name.max(), test.brand_name.max()])+1\nMAX_CONDITION = np.max([train.item_condition_id.max(), test.item_condition_id.max()])+1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f63b427a4c179f60b7c28399c47f1fc336d8a4a9",
        "_cell_guid": "48120d33-f1b1-4c9d-b807-7ea315c87179"
      },
      "cell_type": "markdown",
      "source": "## Pre-trained embeddings"
    },
    {
      "metadata": {
        "_uuid": "5f367f2967d5d4d82bdfa276cd88fceb4b636857",
        "_cell_guid": "e89eae14-78a9-4c9e-8cd0-7759cca71ce4"
      },
      "cell_type": "markdown",
      "source": "### Glove\n"
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "27e542e9fd7ceeae141a1d0eb23f62aff7a261f3",
        "_cell_guid": "73bcd3a6-1929-4df3-8bb0-5201a88ea50b",
        "trusted": false
      },
      "cell_type": "code",
      "source": "def get_embeddings_matrix(embedding_dim):\n    import os    \n    GLOVE_DIR = \"../input/glove100-1\"\n    embeddings_index = {}\n    f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n    for line in f:\n        values = line.split()\n        word = values[0]\n        coefs = np.asarray(values[1:], dtype='float32')\n        embeddings_index[word] = coefs\n\n    f.close()\n\n    print('Total %s word vectors.' % len(embeddings_index))    \n    embedding_matrix = np.random.random((len(word_index) + 1, embedding_dim))\n    for word, i in word_index.items():\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n            # words not found in embedding index will be all-zeros.\n            #print(i, ' ', embedding_vector.shape)\n            embedding_matrix[i] = embedding_vector\n\n    return embedding_matrix",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "16ade7e4d58d6d0585aed1e8975450ead07a9463",
        "_cell_guid": "550833f4-cc00-4ee9-821c-fa3feca15124"
      },
      "cell_type": "markdown",
      "source": "## Target formatting"
    },
    {
      "metadata": {
        "_uuid": "0f0889b7f615aa31316a60088bb8314370ad9109",
        "_cell_guid": "50af7afa-38b2-4abb-8d5b-f0d7547e03b3",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#SCALE target variable\ntrain[\"target\"] = np.log(train.price+1)\ntarget_scaler = MinMaxScaler(feature_range=(-1, 1))\ntrain[\"target\"] = target_scaler.fit_transform(train.target.reshape(-1,1))\npd.DataFrame(train.target).hist()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5a9dd8780e3650b753b7fba105e0e0ddc267c3a1",
        "_cell_guid": "8b3702ec-5f88-4ff2-81fe-f0a7a80f4310"
      },
      "cell_type": "markdown",
      "source": "## Train/Val split"
    },
    {
      "metadata": {
        "_uuid": "85ff1b06b605853985fdad6fbd9a754b921aed01",
        "_cell_guid": "62608036-ceca-430f-93d6-55705af29ea5",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#EXTRACT DEVELOPTMENT TEST\ndtrain, dvalid = train_test_split(train, random_state=123, train_size=0.99)\nprint(dtrain.shape)\nprint(dvalid.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "00bb2450d7f460de5b06d24578eddbe8cbaf1a95",
        "_cell_guid": "8922530c-a119-4127-b06a-67fbfa86cac9",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#KERAS DATA DEFINITION\nfrom keras.preprocessing.sequence import pad_sequences\n\ndef get_keras_data(dataset):\n    seq_item_description_data = np.reshape(list(dataset.seq_item_description), [len(dataset.seq_item_description), MAX_SENTS,MAX_SENT_LENGTH])\n    X = {\n        'name': pad_sequences(dataset.seq_name, maxlen=MAX_NAME_SEQ)\n        ,'item_desc': seq_item_description_data\n        ,'brand_name': np.array(dataset.brand_name)\n        ,'category_name': np.array(dataset.category_name)\n        ,'item_condition': np.array(dataset.item_condition_id)\n        ,'num_vars': np.array(dataset[[\"shipping\"]])\n    }\n    return X\n\nX_train = get_keras_data(dtrain)\nX_valid = get_keras_data(dvalid)\nX_test = get_keras_data(test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0dc76328005931b2502ce871c4c4db8b15dd7a96",
        "_cell_guid": "89b7f156-bf01-44d0-a8ce-76c285ad5d8f"
      },
      "cell_type": "markdown",
      "source": "# Model"
    },
    {
      "metadata": {
        "_uuid": "0b748e17709be7329cbed3d503c680a7413366dd",
        "_cell_guid": "f32ff4dd-e305-4fd5-a5be-8665d4dc2d02",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#KERAS MODEL DEFINITION\nfrom keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, GRU, Embedding, Flatten, BatchNormalization\nfrom keras.models import Model\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom keras import backend as K\n\ndef get_callbacks(filepath, patience=2):\n    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n    msave = ModelCheckpoint(filepath, save_best_only=True)\n    return [es, msave]\n\ndef rmsle_cust(y_true, y_pred):\n    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n    return K.sqrt(K.mean(K.square(first_log - second_log), axis=-1))\n\ndef get_HATT_representation(item_desc_input_layer):\n    \n    # building Hierachical Attention network\n    EMBEDDING_DIM = 100\n    # Pre-trained Embeddings\n    embedding_matrix = get_embeddings_matrix(embedding_dim=EMBEDDING_DIM)\n    \n    embedding_layer = Embedding(len(word_index) + 1,\n                                EMBEDDING_DIM,\n                                weights=[embedding_matrix],\n                                input_length=MAX_SENT_LENGTH,\n                                trainable=True)\n    \n    # Attention\n    from keras.engine.topology import Layer\n    from keras import initializers\n    from keras import backend as K\n    import tensorflow as tf\n    class AttLayer(Layer):\n        def __init__(self, **kwargs):\n            self.init = initializers.VarianceScaling(scale=1.0, mode='fan_in', distribution='normal', seed=None)\n            super(AttLayer, self).__init__(**kwargs)\n\n        def build(self, input_shape):\n            assert len(input_shape)==3\n            self.W = K.variable((self.init((input_shape[-1],1))))\n            self.trainable_weights = [self.W]\n            super(AttLayer, self).build(input_shape)  # be sure you call this somewhere!\n\n        def call(self, x, mask=None):\n            eij = K.tanh(K.dot(x, self.W))\n\n            ai = K.exp(eij)\n            weights = ai/tf.expand_dims(K.sum(ai, axis=1), 1)\n\n            weighted_input = x*weights\n            return tf.reduce_sum(weighted_input, axis=1)\n\n        def compute_output_shape(self, input_shape):\n            return (input_shape[0], input_shape[-1])\n\n\n    \n    # HATT model\n    sentence_input = Input(shape=(MAX_SENT_LENGTH,), dtype='int32')\n    embedded_sequences = embedding_layer(sentence_input)\n\n    l_lstm = Bidirectional(GRU(16, return_sequences=True))(embedded_sequences)\n    l_dense = TimeDistributed(Dense(20))(l_lstm)\n    l_att = AttLayer()(l_dense)\n    sentEncoder = Model(sentence_input, l_att)\n    \n    '''\n    l_lstm = Bidirectional(LSTM(100))(embedded_sequences)\n    sentEncoder = Model(sentence_input, l_lstm)\n    '''\n\n    #review_input = Input(shape=(MAX_SENTS,MAX_SENT_LENGTH), dtype='int32')\n    review_encoder = TimeDistributed(sentEncoder)(item_desc_input_layer)\n\n    '''\n    l_lstm_sent = Bidirectional(LSTM(100))(review_encoder)\n    '''\n\n    \n    l_lstm_sent = Bidirectional(GRU(8, return_sequences=True))(review_encoder)\n    l_dense_sent = TimeDistributed(Dense(20))(l_lstm_sent)\n    l_att_sent = AttLayer()(l_dense_sent)\n    \n    return l_att_sent\n    #return l_lstm_sent\n\ndef get_model():\n    #params\n    dr_r = 0.1\n    \n    #Inputs\n    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n    \n    item_desc = Input(shape=[MAX_SENTS, MAX_SENT_LENGTH], name=\"item_desc\")\n    brand_name = Input(shape=[1], name=\"brand_name\")\n    category_name = Input(shape=[1], name=\"category_name\")\n    item_condition = Input(shape=[1], name=\"item_condition\")\n    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n    \n    #Embeddings layers\n    emb_name = Embedding(MAX_TEXT, 50)(name)\n    #emb_item_desc = Embedding(MAX_TEXT, 50)(item_desc)\n    emb_brand_name = Embedding(MAX_BRAND, 10)(brand_name)\n    emb_category_name = Embedding(MAX_CATEGORY, 10)(category_name)\n    emb_item_condition = Embedding(MAX_CONDITION, 5)(item_condition)\n    \n    #rnn layer\n    HATT_layer = get_HATT_representation(item_desc)\n    rnn_layer2 = GRU(8) (emb_name)\n    \n    #main layer\n    main_l = concatenate([\n        Flatten() (emb_brand_name)\n        , Flatten() (emb_category_name)\n        , Flatten() (emb_item_condition)\n        , HATT_layer\n        , rnn_layer2\n        , num_vars\n    ])\n    main_l = Dropout(dr_r) (Dense(128) (main_l))\n    main_l = Dropout(dr_r) (Dense(64) (main_l))\n    \n    #output\n    output = Dense(1, activation=\"linear\") (main_l)\n    \n    #model\n    model = Model([name, item_desc, brand_name\n                   , category_name, item_condition, num_vars], output)\n    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", rmsle_cust])\n    \n    return model\n\n    \nmodel = get_model()\nmodel.summary()\n'''\nfrom keras.utils.vis_utils import plot_model\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n'''",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c30752fe80ef590d82d2ec949be5cdcc4da97000",
        "_cell_guid": "d1ffd510-04dc-4c53-a1ec-63b4db6c8bcd"
      },
      "cell_type": "markdown",
      "source": "# Train/fit"
    },
    {
      "metadata": {
        "_uuid": "df068628ac583d128138cdae0b7f818e5c75d007",
        "_cell_guid": "f0fb5953-7c52-4d52-ab3c-e5fc0b4e6fea",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#FITTING THE MODEL\nBATCH_SIZE = 20000\nepochs = 5\n\nmodel = get_model()\nmodel.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n          , validation_data=(X_valid, dvalid.target)\n          , verbose=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "aa72df1db8eda43aa6dc607656bf3bf14265a617",
        "_cell_guid": "2d634343-7930-4ecc-a1b7-b8756faee111"
      },
      "cell_type": "markdown",
      "source": "## KFold (TODO)"
    },
    {
      "metadata": {
        "_uuid": "253319719bbb29fa91ff7174c8aee290a122812e",
        "_cell_guid": "907d8c8e-db89-4e5c-966f-fa892c3f15d9"
      },
      "cell_type": "markdown",
      "source": "# Evaulate"
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "fb7ee60afd08ccb1f783b5be7b54cfc61bf8a731",
        "_cell_guid": "688b35c7-0cf6-44f7-b09e-036b419b7cb0",
        "trusted": false
      },
      "cell_type": "code",
      "source": "def rmsle(y, y_pred):\n    assert len(y) == len(y_pred)\n    to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n    return (sum(to_sum) * (1.0/len(y))) ** 0.5\n#Source: https://www.kaggle.com/marknagelberg/rmsle-function",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "053ff8618e952ca2f331341e74aaa03093183721",
        "_cell_guid": "3bb61e4a-9196-4286-be28-44e308cf29a1",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#EVLUEATE THE MODEL ON DEV TEST: What is it doing?\nval_preds = model.predict(X_valid)\nval_preds = target_scaler.inverse_transform(val_preds)\nval_preds = np.exp(val_preds)+1\n\n#mean_absolute_error, mean_squared_log_error\ny_true = np.array(dvalid.price.values)\ny_pred = val_preds[:,0]\nv_rmsle = rmsle(y_true, y_pred)\nprint(\" RMSLE error on dev test: \"+str(v_rmsle))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "02685bc8ec4da4171f1ec221f30a3e96f4e8861e",
        "_cell_guid": "2eb08bdf-7f69-4e3a-85cf-8b77dfaddfdb"
      },
      "cell_type": "markdown",
      "source": "# Submit"
    },
    {
      "metadata": {
        "_uuid": "918c87259d92f95d12d29b76c9b7c5abec32b6cf",
        "_cell_guid": "aa9b9280-5c3e-48fa-8e7f-4da550ec3c3c",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#CREATE PREDICTIONS\npreds = model.predict(X_test, batch_size=BATCH_SIZE)\npreds = target_scaler.inverse_transform(preds)\npreds = np.exp(preds)-1\n\nsubmission = test[[\"test_id\"]]\nsubmission[\"price\"] = preds",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cd7274a5e801d4b1e3fbb8382aad43a854980c2d",
        "_cell_guid": "8ae1690c-7d64-44dc-b21c-fbdb7d1873e6",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "submission.to_csv(\"./myNNsubmission.csv\", index=False)\nsubmission.price.hist()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "af252cacd9976161818ef5cb9b882fa6bf76a925",
        "_cell_guid": "f8b2b278-b867-4aa7-9adc-9b65a4f195a3"
      },
      "cell_type": "markdown",
      "source": "# Reference\n\n\nhttps://www.kaggle.com/knowledgegrappler/a-simple-nn-solution-with-keras-0-48611-pl"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "anaconda-cloud": {}
  },
  "nbformat": 4,
  "nbformat_minor": 1
}