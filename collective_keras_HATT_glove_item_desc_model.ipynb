{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import math\n",
    "from nltk import tokenize\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Merge, Dropout, LSTM, GRU, Bidirectional, TimeDistributed\n",
    "from keras.models import Model\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded\n",
      "(1482535, 8)\n",
      "(693359, 7)\n"
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "print(\"Loading data...\")\n",
    "train = pd.read_table(\"../../dat/train.tsv\")\n",
    "test = pd.read_table(\"../../dat/test.tsv\")\n",
    "print('Data loaded')\n",
    "print(train.shape)\n",
    "print(test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values...\n",
      "(1482535, 8)\n",
      "(693359, 7)\n"
     ]
    }
   ],
   "source": [
    "#HANDLE MISSING VALUES\n",
    "print(\"Handling missing values...\")\n",
    "def handle_missing(dataset):\n",
    "    dataset.category_name.fillna(value=\"missing\", inplace=True)\n",
    "    dataset.brand_name.fillna(value=\"missing\", inplace=True)\n",
    "    dataset.item_description.fillna(value=\"missing\", inplace=True)\n",
    "    return (dataset)\n",
    "\n",
    "train = handle_missing(train)\n",
    "test = handle_missing(test)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>missing</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>Razer</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>Target</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                 name  item_condition_id  \\\n",
       "0         0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1         1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2         2                       AVA-VIV Blouse                  1   \n",
       "\n",
       "                                       category_name brand_name  price  \\\n",
       "0                                  Men/Tops/T-shirts    missing     10   \n",
       "1  Electronics/Computers & Tablets/Components & P...      Razer     52   \n",
       "2                        Women/Tops & Blouses/Blouse     Target     10   \n",
       "\n",
       "   shipping                                   item_description  \n",
       "0         1                                 No description yet  \n",
       "1         0  This keyboard is in great condition and works ...  \n",
       "2         1  Adorable top with a hint of lace and a key hol...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle categorial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling categorical variables...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>829</td>\n",
       "      <td>5265</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "      <td>3889</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>1277</td>\n",
       "      <td>4588</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                 name  item_condition_id  \\\n",
       "0         0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1         1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2         2                       AVA-VIV Blouse                  1   \n",
       "\n",
       "   category_name  brand_name  price  shipping  \\\n",
       "0            829        5265     10         1   \n",
       "1             86        3889     52         0   \n",
       "2           1277        4588     10         1   \n",
       "\n",
       "                                    item_description  \n",
       "0                                 No description yet  \n",
       "1  This keyboard is in great condition and works ...  \n",
       "2  Adorable top with a hint of lace and a key hol...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PROCESS CATEGORICAL DATA\n",
    "print(\"Handling categorical variables...\")\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(np.hstack([train.category_name, test.category_name]))\n",
    "train.category_name = le.transform(train.category_name)\n",
    "test.category_name = le.transform(test.category_name)\n",
    "\n",
    "le.fit(np.hstack([train.brand_name, test.brand_name]))\n",
    "train.brand_name = le.transform(train.brand_name)\n",
    "test.brand_name = le.transform(test.brand_name)\n",
    "del le\n",
    "\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to seq process...\n",
      "   Transforming text to seq of sentences, which is a sequence of words...\n",
      "   Fitting tokenizer...\n",
      "Total 259198 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "#PROCESS TEXT: RAW\n",
    "print(\"Text to seq process...\")\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "raw_text = np.hstack([train.item_description.str.lower(), train.name.str.lower()])\n",
    "print(\"   Transforming text to seq of sentences, which is a sequence of words...\")\n",
    "print(\"   Fitting tokenizer...\")\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(raw_text)\n",
    "word_index = tokenizer.word_index\n",
    "print('Total %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "MAX_SENTS = 5\n",
    "MAX_SENT_LENGTH = 25\n",
    "MAX_NB_WORDS = 20000\n",
    "def process_hierarichal_text(descriptions_raw):\n",
    "    descriptions = []\n",
    "    for description in descriptions_raw:\n",
    "        \n",
    "        sentences = tokenize.sent_tokenize(description.decode('utf8'))        \n",
    "        #sentences = tokenize.sent_tokenize(description)\n",
    "        \n",
    "        '''\n",
    "        MAX_SENTS = max(MAX_SENTS, len(sentences))\n",
    "        for sent in sentences:\n",
    "            MAX_SENT_LENGTH = max(MAX_SENT_LENGTH, len(tok_raw.texts_to_sequences(sent)))\n",
    "        '''\n",
    "        descriptions.append(sentences)\n",
    "    #print('MAX_SENTS = ', MAX_SENTS)\n",
    "    #print('MAX_SENT_LENGTH = ', MAX_SENT_LENGTH)\n",
    "\n",
    "    data = np.zeros((len(descriptions_raw), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
    "    #n_errs = 0\n",
    "    for i, description in enumerate(descriptions):\n",
    "        sent_words_indices = tokenizer.texts_to_sequences(description)\n",
    "        for j in range(len(sent_words_indices)):\n",
    "            if j< MAX_SENTS:\n",
    "                for k in range(len(sent_words_indices[j])):\n",
    "                    word_idx = sent_words_indices[j][k]\n",
    "                    if k < MAX_SENT_LENGTH and word_idx < MAX_NB_WORDS:\n",
    "                        data[i,j,k] = word_idx\n",
    "                        #print(data[i,j,k])\n",
    "                    \n",
    "    #print('Total errors=', n_errs)\n",
    "    #print(data)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 259198 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "print('Total %s unique tokens.' % len(word_index))\n",
    "\n",
    "train_seq_item_desc = process_hierarichal_text(train.item_description.str.lower())\n",
    "test_seq_item_desc = process_hierarichal_text(test.item_description.str.lower())\n",
    " \n",
    "train[\"seq_item_description\"] = list(train_seq_item_desc)\n",
    "test[\"seq_item_description\"] = list(test_seq_item_desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>seq_item_description</th>\n",
       "      <th>seq_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>829</td>\n",
       "      <td>5265</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "      <td>[[12, 68, 79, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[3851, 8822, 6896, 208, 84, 6, 155]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "      <td>3889</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "      <td>[[29, 2627, 10, 7, 39, 17, 1, 207, 51, 19, 111...</td>\n",
       "      <td>[10759, 25570, 16366, 2627]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>1277</td>\n",
       "      <td>4588</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "      <td>[[604, 60, 9, 4, 5347, 11, 192, 1, 4, 886, 129...</td>\n",
       "      <td>[7634, 10563, 666]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                 name  item_condition_id  \\\n",
       "0         0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1         1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2         2                       AVA-VIV Blouse                  1   \n",
       "\n",
       "   category_name  brand_name  price  shipping  \\\n",
       "0            829        5265     10         1   \n",
       "1             86        3889     52         0   \n",
       "2           1277        4588     10         1   \n",
       "\n",
       "                                    item_description  \\\n",
       "0                                 No description yet   \n",
       "1  This keyboard is in great condition and works ...   \n",
       "2  Adorable top with a hint of lace and a key hol...   \n",
       "\n",
       "                                seq_item_description  \\\n",
       "0  [[12, 68, 79, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1  [[29, 2627, 10, 7, 39, 17, 1, 207, 51, 19, 111...   \n",
       "2  [[604, 60, 9, 4, 5347, 11, 192, 1, 4, 886, 129...   \n",
       "\n",
       "                              seq_name  \n",
       "0  [3851, 8822, 6896, 208, 84, 6, 155]  \n",
       "1          [10759, 25570, 16366, 2627]  \n",
       "2                   [7634, 10563, 666]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"seq_name\"] = tokenizer.texts_to_sequences(train.name.str.lower())\n",
    "test[\"seq_name\"] = tokenizer.texts_to_sequences(test.name.str.lower())\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings size calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max name seq 17\n",
      "max item desc seq 5\n"
     ]
    }
   ],
   "source": [
    "#SEQUENCES VARIABLES ANALYSIS\n",
    "max_name_seq = np.max([np.max(train.seq_name.apply(lambda x: len(x))), np.max(test.seq_name.apply(lambda x: len(x)))])\n",
    "max_seq_item_description = np.max([np.max(train.seq_item_description.apply(lambda x: len(x)))\n",
    "                                   , np.max(test.seq_item_description.apply(lambda x: len(x)))])\n",
    "print(\"max name seq \"+str(max_name_seq))\n",
    "print(\"max item desc seq \"+str(max_seq_item_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#EMBEDDINGS MAX VALUE\n",
    "#Base on the histograms, we select the next lengths\n",
    "MAX_NAME_SEQ = 10\n",
    "#MAX_ITEM_DESC_SEQ = 75\n",
    "MAX_TEXT = np.max([np.max(train.seq_name.max())\n",
    "                   , np.max(test.seq_name.max())])+2\n",
    "MAX_CATEGORY = np.max([train.category_name.max(), test.category_name.max()])+1\n",
    "MAX_BRAND = np.max([train.brand_name.max(), test.brand_name.max()])+1\n",
    "MAX_CONDITION = np.max([train.item_condition_id.max(), test.item_condition_id.max()])+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_embeddings_matrix(embedding_dim):\n",
    "    import os    \n",
    "    GLOVE_DIR = \"../../dat/glove\"\n",
    "    embeddings_index = {}\n",
    "    f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    print('Total %s word vectors.' % len(embeddings_index))    \n",
    "    embedding_matrix = np.random.random((len(word_index) + 1, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            #print(i, ' ', embedding_vector.shape)\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f3c24fe8f90>]], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3c7a5d1b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#SCALE target variable\n",
    "train[\"target\"] = np.log(train.price+1)\n",
    "target_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train[\"target\"] = target_scaler.fit_transform(train.target.reshape(-1,1))\n",
    "pd.DataFrame(train.target).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1467709, 11)\n",
      "(14826, 11)\n"
     ]
    }
   ],
   "source": [
    "#EXTRACT DEVELOPTMENT TEST\n",
    "dtrain, dvalid = train_test_split(train, random_state=123, train_size=0.99)\n",
    "print(dtrain.shape)\n",
    "print(dvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#KERAS DATA DEFINITION\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def get_keras_data(dataset):\n",
    "    seq_item_description_data = np.reshape(list(dataset.seq_item_description), [len(dataset.seq_item_description), MAX_SENTS,MAX_SENT_LENGTH])\n",
    "    X = {\n",
    "        'name': pad_sequences(dataset.seq_name, maxlen=MAX_NAME_SEQ)\n",
    "        ,'item_desc': seq_item_description_data\n",
    "        ,'brand_name': np.array(dataset.brand_name)\n",
    "        ,'category_name': np.array(dataset.category_name)\n",
    "        ,'item_condition': np.array(dataset.item_condition_id)\n",
    "        ,'num_vars': np.array(dataset[[\"shipping\"]])\n",
    "    }\n",
    "    return X\n",
    "\n",
    "X_train = get_keras_data(dtrain)\n",
    "X_valid = get_keras_data(dvalid)\n",
    "X_test = get_keras_data(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 7396 word vectors.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "item_desc (InputLayer)          (None, 5, 25)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_14 (TimeDistri (None, 5, 20)        25931812    item_desc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "brand_name (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "category_name (InputLayer)      (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_condition (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 5, 16)        1392        time_distributed_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "name (InputLayer)               (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_63 (Embedding)        (None, 1, 10)        52900       brand_name[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_64 (Embedding)        (None, 1, 10)        13110       category_name[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_65 (Embedding)        (None, 1, 5)         30          item_condition[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_15 (TimeDistri (None, 5, 20)        340         bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_62 (Embedding)        (None, 10, 50)       12959950    name[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 10)           0           embedding_63[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 10)           0           embedding_64[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 5)            0           embedding_65[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "att_layer_10 (AttLayer)         (None, 20)           20          time_distributed_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "gru_15 (GRU)                    (None, 8)            1416        embedding_62[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "num_vars (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 54)           0           flatten_13[0][0]                 \n",
      "                                                                 flatten_14[0][0]                 \n",
      "                                                                 flatten_15[0][0]                 \n",
      "                                                                 att_layer_10[0][0]               \n",
      "                                                                 gru_15[0][0]                     \n",
      "                                                                 num_vars[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 128)          7040        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 128)          0           dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 64)           8256        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 64)           0           dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 1)            65          dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 38,976,331\n",
      "Trainable params: 38,976,331\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfrom keras.utils.vis_utils import plot_model\\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KERAS MODEL DEFINITION\n",
    "from keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, GRU, Embedding, Flatten, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras import backend as K\n",
    "\n",
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave]\n",
    "\n",
    "def rmsle_cust(y_true, y_pred):\n",
    "    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n",
    "    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n",
    "    return K.sqrt(K.mean(K.square(first_log - second_log), axis=-1))\n",
    "\n",
    "def get_HATT_representation(item_desc_input_layer):\n",
    "    \n",
    "    # building Hierachical Attention network\n",
    "    EMBEDDING_DIM = 100\n",
    "    # Pre-trained Embeddings\n",
    "    embedding_matrix = get_embeddings_matrix(embedding_dim=EMBEDDING_DIM)\n",
    "    \n",
    "    embedding_layer = Embedding(len(word_index) + 1,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=MAX_SENT_LENGTH,\n",
    "                                trainable=True)\n",
    "    \n",
    "    # Attention\n",
    "    from keras.engine.topology import Layer\n",
    "    from keras import initializers\n",
    "    from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "    class AttLayer(Layer):\n",
    "        def __init__(self, **kwargs):\n",
    "            self.init = initializers.VarianceScaling(scale=1.0, mode='fan_in', distribution='normal', seed=None)\n",
    "            super(AttLayer, self).__init__(**kwargs)\n",
    "\n",
    "        def build(self, input_shape):\n",
    "            assert len(input_shape)==3\n",
    "            self.W = K.variable((self.init((input_shape[-1],1))))\n",
    "            self.trainable_weights = [self.W]\n",
    "            super(AttLayer, self).build(input_shape)  # be sure you call this somewhere!\n",
    "\n",
    "        def call(self, x, mask=None):\n",
    "            eij = K.tanh(K.dot(x, self.W))\n",
    "\n",
    "            ai = K.exp(eij)\n",
    "            weights = ai/tf.expand_dims(K.sum(ai, axis=1), 1)\n",
    "\n",
    "            weighted_input = x*weights\n",
    "            return tf.reduce_sum(weighted_input, axis=1)\n",
    "\n",
    "        def compute_output_shape(self, input_shape):\n",
    "            return (input_shape[0], input_shape[-1])\n",
    "\n",
    "\n",
    "    \n",
    "    # HATT model\n",
    "    sentence_input = Input(shape=(MAX_SENT_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sentence_input)\n",
    "\n",
    "    l_lstm = Bidirectional(GRU(16, return_sequences=True))(embedded_sequences)\n",
    "    l_dense = TimeDistributed(Dense(20))(l_lstm)\n",
    "    l_att = AttLayer()(l_dense)\n",
    "    sentEncoder = Model(sentence_input, l_att)\n",
    "    \n",
    "    '''\n",
    "    l_lstm = Bidirectional(LSTM(100))(embedded_sequences)\n",
    "    sentEncoder = Model(sentence_input, l_lstm)\n",
    "    '''\n",
    "\n",
    "    #review_input = Input(shape=(MAX_SENTS,MAX_SENT_LENGTH), dtype='int32')\n",
    "    review_encoder = TimeDistributed(sentEncoder)(item_desc_input_layer)\n",
    "\n",
    "    '''\n",
    "    l_lstm_sent = Bidirectional(LSTM(100))(review_encoder)\n",
    "    '''\n",
    "\n",
    "    \n",
    "    l_lstm_sent = Bidirectional(GRU(8, return_sequences=True))(review_encoder)\n",
    "    l_dense_sent = TimeDistributed(Dense(20))(l_lstm_sent)\n",
    "    l_att_sent = AttLayer()(l_dense_sent)\n",
    "    \n",
    "    return l_att_sent\n",
    "    #return l_lstm_sent\n",
    "\n",
    "def get_model():\n",
    "    #params\n",
    "    dr_r = 0.1\n",
    "    \n",
    "    #Inputs\n",
    "    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n",
    "    \n",
    "    item_desc = Input(shape=[MAX_SENTS, MAX_SENT_LENGTH], name=\"item_desc\")\n",
    "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
    "    category_name = Input(shape=[1], name=\"category_name\")\n",
    "    item_condition = Input(shape=[1], name=\"item_condition\")\n",
    "    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n",
    "    \n",
    "    #Embeddings layers\n",
    "    emb_name = Embedding(MAX_TEXT, 50)(name)\n",
    "    #emb_item_desc = Embedding(MAX_TEXT, 50)(item_desc)\n",
    "    emb_brand_name = Embedding(MAX_BRAND, 10)(brand_name)\n",
    "    emb_category_name = Embedding(MAX_CATEGORY, 10)(category_name)\n",
    "    emb_item_condition = Embedding(MAX_CONDITION, 5)(item_condition)\n",
    "    \n",
    "    #rnn layer\n",
    "    HATT_layer = get_HATT_representation(item_desc)\n",
    "    rnn_layer2 = GRU(8) (emb_name)\n",
    "    \n",
    "    #main layer\n",
    "    main_l = concatenate([\n",
    "        Flatten() (emb_brand_name)\n",
    "        , Flatten() (emb_category_name)\n",
    "        , Flatten() (emb_item_condition)\n",
    "        , HATT_layer\n",
    "        , rnn_layer2\n",
    "        , num_vars\n",
    "    ])\n",
    "    main_l = Dropout(dr_r) (Dense(128) (main_l))\n",
    "    main_l = Dropout(dr_r) (Dense(64) (main_l))\n",
    "    \n",
    "    #output\n",
    "    output = Dense(1, activation=\"linear\") (main_l)\n",
    "    \n",
    "    #model\n",
    "    import keras.optimizers\n",
    "    lr = 0.01\n",
    "    opt = keras.optimizers.adagrad(lr)\n",
    "    model = Model([name, item_desc, brand_name\n",
    "                   , category_name, item_condition, num_vars], output)\n",
    "    model.compile(loss=\"mse\", optimizer=opt, metrics=[\"mae\", rmsle_cust])\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "model = get_model()\n",
    "model.summary()\n",
    "'''\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 7396 word vectors.\n",
      "Train on 1467709 samples, validate on 14826 samples\n",
      "Epoch 1/20\n",
      "1467709/1467709 [==============================] - 50s 34us/step - loss: 0.1356 - mean_absolute_error: 0.1880 - rmsle_cust: 0.0246 - val_loss: 0.0206 - val_mean_absolute_error: 0.1095 - val_rmsle_cust: 0.0143\n",
      "Epoch 2/20\n",
      "1467709/1467709 [==============================] - 48s 32us/step - loss: 0.0242 - mean_absolute_error: 0.1198 - rmsle_cust: 0.0148 - val_loss: 0.0183 - val_mean_absolute_error: 0.1026 - val_rmsle_cust: 0.0135\n",
      "Epoch 3/20\n",
      "1467709/1467709 [==============================] - 48s 33us/step - loss: 0.0209 - mean_absolute_error: 0.1108 - rmsle_cust: 0.0139 - val_loss: 0.0175 - val_mean_absolute_error: 0.0999 - val_rmsle_cust: 0.0131\n",
      "Epoch 4/20\n",
      "1467709/1467709 [==============================] - 48s 33us/step - loss: 0.0192 - mean_absolute_error: 0.1058 - rmsle_cust: 0.0134 - val_loss: 0.0171 - val_mean_absolute_error: 0.0987 - val_rmsle_cust: 0.0130\n",
      "Epoch 5/20\n",
      "1467709/1467709 [==============================] - 48s 32us/step - loss: 0.0182 - mean_absolute_error: 0.1026 - rmsle_cust: 0.0130 - val_loss: 0.0169 - val_mean_absolute_error: 0.0978 - val_rmsle_cust: 0.0129\n",
      "Epoch 6/20\n",
      "1467709/1467709 [==============================] - 48s 33us/step - loss: 0.0175 - mean_absolute_error: 0.1003 - rmsle_cust: 0.0128 - val_loss: 0.0168 - val_mean_absolute_error: 0.0976 - val_rmsle_cust: 0.0128\n",
      "Epoch 7/20\n",
      "1467709/1467709 [==============================] - 48s 33us/step - loss: 0.0169 - mean_absolute_error: 0.0986 - rmsle_cust: 0.0126 - val_loss: 0.0167 - val_mean_absolute_error: 0.0977 - val_rmsle_cust: 0.0128\n",
      "Epoch 8/20\n",
      "1467709/1467709 [==============================] - 48s 33us/step - loss: 0.0165 - mean_absolute_error: 0.0973 - rmsle_cust: 0.0124 - val_loss: 0.0167 - val_mean_absolute_error: 0.0979 - val_rmsle_cust: 0.0128\n",
      "Epoch 9/20\n",
      "1467709/1467709 [==============================] - 48s 33us/step - loss: 0.0162 - mean_absolute_error: 0.0961 - rmsle_cust: 0.0123 - val_loss: 0.0165 - val_mean_absolute_error: 0.0971 - val_rmsle_cust: 0.0128\n",
      "Epoch 10/20\n",
      "1467709/1467709 [==============================] - 48s 33us/step - loss: 0.0159 - mean_absolute_error: 0.0951 - rmsle_cust: 0.0122 - val_loss: 0.0165 - val_mean_absolute_error: 0.0971 - val_rmsle_cust: 0.0128\n",
      "Epoch 11/20\n",
      "1467709/1467709 [==============================] - 48s 33us/step - loss: 0.0156 - mean_absolute_error: 0.0941 - rmsle_cust: 0.0121 - val_loss: 0.0165 - val_mean_absolute_error: 0.0972 - val_rmsle_cust: 0.0127\n",
      "Epoch 12/20\n",
      "1467709/1467709 [==============================] - 48s 33us/step - loss: 0.0154 - mean_absolute_error: 0.0935 - rmsle_cust: 0.0120 - val_loss: 0.0164 - val_mean_absolute_error: 0.0965 - val_rmsle_cust: 0.0127\n",
      "Epoch 13/20\n",
      "1467709/1467709 [==============================] - 48s 33us/step - loss: 0.0152 - mean_absolute_error: 0.0928 - rmsle_cust: 0.0119 - val_loss: 0.0163 - val_mean_absolute_error: 0.0963 - val_rmsle_cust: 0.0127\n",
      "Epoch 14/20\n",
      "1467709/1467709 [==============================] - 48s 33us/step - loss: 0.0151 - mean_absolute_error: 0.0923 - rmsle_cust: 0.0118 - val_loss: 0.0163 - val_mean_absolute_error: 0.0967 - val_rmsle_cust: 0.0127\n",
      "Epoch 15/20\n",
      "1467709/1467709 [==============================] - 48s 33us/step - loss: 0.0149 - mean_absolute_error: 0.0916 - rmsle_cust: 0.0118 - val_loss: 0.0162 - val_mean_absolute_error: 0.0965 - val_rmsle_cust: 0.0127\n",
      "Epoch 16/20\n",
      "1467709/1467709 [==============================] - 48s 33us/step - loss: 0.0147 - mean_absolute_error: 0.0912 - rmsle_cust: 0.0117 - val_loss: 0.0163 - val_mean_absolute_error: 0.0969 - val_rmsle_cust: 0.0127\n",
      "Epoch 17/20\n",
      "1467709/1467709 [==============================] - 48s 33us/step - loss: 0.0146 - mean_absolute_error: 0.0907 - rmsle_cust: 0.0117 - val_loss: 0.0161 - val_mean_absolute_error: 0.0957 - val_rmsle_cust: 0.0126\n",
      "Epoch 18/20\n",
      "1467709/1467709 [==============================] - 48s 33us/step - loss: 0.0145 - mean_absolute_error: 0.0903 - rmsle_cust: 0.0116 - val_loss: 0.0161 - val_mean_absolute_error: 0.0961 - val_rmsle_cust: 0.0127\n",
      "Epoch 19/20\n",
      "1467709/1467709 [==============================] - 48s 33us/step - loss: 0.0144 - mean_absolute_error: 0.0899 - rmsle_cust: 0.0115 - val_loss: 0.0160 - val_mean_absolute_error: 0.0959 - val_rmsle_cust: 0.0126\n",
      "Epoch 20/20\n",
      "1467709/1467709 [==============================] - 48s 33us/step - loss: 0.0142 - mean_absolute_error: 0.0894 - rmsle_cust: 0.0115 - val_loss: 0.0160 - val_mean_absolute_error: 0.0957 - val_rmsle_cust: 0.0126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c379254d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FITTING THE MODEL\n",
    "BATCH_SIZE = 10000\n",
    "epochs = 20\n",
    "\n",
    "model = get_model()\n",
    "model.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n",
    "          , validation_data=(X_valid, dvalid.target)\n",
    "          , verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFold (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    assert len(y) == len(y_pred)\n",
    "    to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n",
    "    return (sum(to_sum) * (1.0/len(y))) ** 0.5\n",
    "#Source: https://www.kaggle.com/marknagelberg/rmsle-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSLE error on dev test: 0.492505160567\n"
     ]
    }
   ],
   "source": [
    "#EVLUEATE THE MODEL ON DEV TEST: What is it doing?\n",
    "val_preds = model.predict(X_valid)\n",
    "val_preds = target_scaler.inverse_transform(val_preds)\n",
    "val_preds = np.exp(val_preds)+1\n",
    "\n",
    "#mean_absolute_error, mean_squared_log_error\n",
    "y_true = np.array(dvalid.price.values)\n",
    "y_pred = val_preds[:,0]\n",
    "v_rmsle = rmsle(y_true, y_pred)\n",
    "print(\" RMSLE error on dev test: \"+str(v_rmsle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#CREATE PREDICTIONS\n",
    "preds = model.predict(X_test, batch_size=BATCH_SIZE)\n",
    "preds = target_scaler.inverse_transform(preds)\n",
    "preds = np.exp(preds)-1\n",
    "\n",
    "submission = test[[\"test_id\"]]\n",
    "submission[\"price\"] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3c52002cd0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEACAYAAAB27puMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3c32531f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission.to_csv(\"./myNNsubmission.csv\", index=False)\n",
    "submission.price.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "\n",
    "https://www.kaggle.com/knowledgegrappler/a-simple-nn-solution-with-keras-0-48611-pl"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
