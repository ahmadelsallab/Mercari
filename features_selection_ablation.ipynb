{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import math\n",
    "from nltk import tokenize\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Merge, Dropout, LSTM, GRU, Bidirectional, TimeDistributed\n",
    "from keras.models import Model\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded\n",
      "(1482535, 8)\n",
      "(693359, 7)\n"
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "print(\"Loading data...\")\n",
    "train = pd.read_table(\"../../dat/train.tsv\")\n",
    "test = pd.read_table(\"../../dat/test.tsv\")\n",
    "print('Data loaded')\n",
    "print(train.shape)\n",
    "print(test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values...\n",
      "(1482535, 8)\n",
      "(693359, 7)\n"
     ]
    }
   ],
   "source": [
    "#HANDLE MISSING VALUES\n",
    "print(\"Handling missing values...\")\n",
    "def handle_missing(dataset):\n",
    "    dataset.category_name.fillna(value=\"missing\", inplace=True)\n",
    "    dataset.brand_name.fillna(value=\"missing\", inplace=True)\n",
    "    dataset.item_description.fillna(value=\"missing\", inplace=True)\n",
    "    return (dataset)\n",
    "\n",
    "train = handle_missing(train)\n",
    "test = handle_missing(test)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>missing</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>Razer</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>Target</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                 name  item_condition_id  \\\n",
       "0         0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1         1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2         2                       AVA-VIV Blouse                  1   \n",
       "\n",
       "                                       category_name brand_name  price  \\\n",
       "0                                  Men/Tops/T-shirts    missing     10   \n",
       "1  Electronics/Computers & Tablets/Components & P...      Razer     52   \n",
       "2                        Women/Tops & Blouses/Blouse     Target     10   \n",
       "\n",
       "   shipping                                   item_description  \n",
       "0         1                                 No description yet  \n",
       "1         0  This keyboard is in great condition and works ...  \n",
       "2         1  Adorable top with a hint of lace and a key hol...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle categorial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling categorical variables...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>829</td>\n",
       "      <td>5265</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "      <td>3889</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>1277</td>\n",
       "      <td>4588</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                 name  item_condition_id  \\\n",
       "0         0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1         1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2         2                       AVA-VIV Blouse                  1   \n",
       "\n",
       "   category_name  brand_name  price  shipping  \\\n",
       "0            829        5265     10         1   \n",
       "1             86        3889     52         0   \n",
       "2           1277        4588     10         1   \n",
       "\n",
       "                                    item_description  \n",
       "0                                 No description yet  \n",
       "1  This keyboard is in great condition and works ...  \n",
       "2  Adorable top with a hint of lace and a key hol...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PROCESS CATEGORICAL DATA\n",
    "print(\"Handling categorical variables...\")\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(np.hstack([train.category_name, test.category_name]))\n",
    "train.category_name = le.transform(train.category_name)\n",
    "test.category_name = le.transform(test.category_name)\n",
    "\n",
    "le.fit(np.hstack([train.brand_name, test.brand_name]))\n",
    "train.brand_name = le.transform(train.brand_name)\n",
    "test.brand_name = le.transform(test.brand_name)\n",
    "del le\n",
    "\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to seq process...\n",
      "   Transforming text to seq of sentences, which is a sequence of words...\n",
      "   Fitting tokenizer...\n",
      "Total 259198 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "#PROCESS TEXT: RAW\n",
    "print(\"Text to seq process...\")\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "raw_text = np.hstack([train.item_description.str.lower(), train.name.str.lower()])\n",
    "print(\"   Transforming text to seq of sentences, which is a sequence of words...\")\n",
    "print(\"   Fitting tokenizer...\")\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(raw_text)\n",
    "word_index = tokenizer.word_index\n",
    "print('Total %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "MAX_SENTS = 5\n",
    "MAX_SENT_LENGTH = 25\n",
    "MAX_NB_WORDS = 20000\n",
    "def process_hierarichal_text(descriptions_raw):\n",
    "    descriptions = []\n",
    "    for description in descriptions_raw:\n",
    "        \n",
    "        sentences = tokenize.sent_tokenize(description.decode('utf8'))        \n",
    "        #sentences = tokenize.sent_tokenize(description)\n",
    "        \n",
    "        '''\n",
    "        MAX_SENTS = max(MAX_SENTS, len(sentences))\n",
    "        for sent in sentences:\n",
    "            MAX_SENT_LENGTH = max(MAX_SENT_LENGTH, len(tok_raw.texts_to_sequences(sent)))\n",
    "        '''\n",
    "        descriptions.append(sentences)\n",
    "    #print('MAX_SENTS = ', MAX_SENTS)\n",
    "    #print('MAX_SENT_LENGTH = ', MAX_SENT_LENGTH)\n",
    "\n",
    "    data = np.zeros((len(descriptions_raw), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
    "    #n_errs = 0\n",
    "    for i, description in enumerate(descriptions):\n",
    "        sent_words_indices = tokenizer.texts_to_sequences(description)\n",
    "        for j in range(len(sent_words_indices)):\n",
    "            if j< MAX_SENTS:\n",
    "                for k in range(len(sent_words_indices[j])):\n",
    "                    word_idx = sent_words_indices[j][k]\n",
    "                    if k < MAX_SENT_LENGTH and word_idx < MAX_NB_WORDS:\n",
    "                        data[i,j,k] = word_idx\n",
    "                        #print(data[i,j,k])\n",
    "                    \n",
    "    #print('Total errors=', n_errs)\n",
    "    #print(data)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 259198 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "print('Total %s unique tokens.' % len(word_index))\n",
    "\n",
    "train_seq_item_desc = process_hierarichal_text(train.item_description.str.lower())\n",
    "test_seq_item_desc = process_hierarichal_text(test.item_description.str.lower())\n",
    " \n",
    "train[\"seq_item_description\"] = list(train_seq_item_desc)\n",
    "test[\"seq_item_description\"] = list(test_seq_item_desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>seq_item_description</th>\n",
       "      <th>seq_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>829</td>\n",
       "      <td>5265</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "      <td>[[12, 68, 79, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[3851, 8822, 6896, 208, 84, 6, 155]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "      <td>3889</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "      <td>[[29, 2627, 10, 7, 39, 17, 1, 207, 51, 19, 111...</td>\n",
       "      <td>[10759, 25570, 16366, 2627]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>1277</td>\n",
       "      <td>4588</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "      <td>[[604, 60, 9, 4, 5347, 11, 192, 1, 4, 886, 129...</td>\n",
       "      <td>[7634, 10563, 666]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                 name  item_condition_id  \\\n",
       "0         0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1         1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2         2                       AVA-VIV Blouse                  1   \n",
       "\n",
       "   category_name  brand_name  price  shipping  \\\n",
       "0            829        5265     10         1   \n",
       "1             86        3889     52         0   \n",
       "2           1277        4588     10         1   \n",
       "\n",
       "                                    item_description  \\\n",
       "0                                 No description yet   \n",
       "1  This keyboard is in great condition and works ...   \n",
       "2  Adorable top with a hint of lace and a key hol...   \n",
       "\n",
       "                                seq_item_description  \\\n",
       "0  [[12, 68, 79, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1  [[29, 2627, 10, 7, 39, 17, 1, 207, 51, 19, 111...   \n",
       "2  [[604, 60, 9, 4, 5347, 11, 192, 1, 4, 886, 129...   \n",
       "\n",
       "                              seq_name  \n",
       "0  [3851, 8822, 6896, 208, 84, 6, 155]  \n",
       "1          [10759, 25570, 16366, 2627]  \n",
       "2                   [7634, 10563, 666]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"seq_name\"] = tokenizer.texts_to_sequences(train.name.str.lower())\n",
    "test[\"seq_name\"] = tokenizer.texts_to_sequences(test.name.str.lower())\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings size calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max name seq 17\n",
      "max item desc seq 5\n"
     ]
    }
   ],
   "source": [
    "#SEQUENCES VARIABLES ANALYSIS\n",
    "max_name_seq = np.max([np.max(train.seq_name.apply(lambda x: len(x))), np.max(test.seq_name.apply(lambda x: len(x)))])\n",
    "max_seq_item_description = np.max([np.max(train.seq_item_description.apply(lambda x: len(x)))\n",
    "                                   , np.max(test.seq_item_description.apply(lambda x: len(x)))])\n",
    "print(\"max name seq \"+str(max_name_seq))\n",
    "print(\"max item desc seq \"+str(max_seq_item_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#EMBEDDINGS MAX VALUE\n",
    "#Base on the histograms, we select the next lengths\n",
    "MAX_NAME_SEQ = 10\n",
    "#MAX_ITEM_DESC_SEQ = 75\n",
    "MAX_TEXT = np.max([np.max(train.seq_name.max())\n",
    "                   , np.max(test.seq_name.max())])+2\n",
    "MAX_CATEGORY = np.max([train.category_name.max(), test.category_name.max()])+1\n",
    "MAX_BRAND = np.max([train.brand_name.max(), test.brand_name.max()])+1\n",
    "MAX_CONDITION = np.max([train.item_condition_id.max(), test.item_condition_id.max()])+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_embeddings_matrix(embedding_dim):\n",
    "    import os    \n",
    "    GLOVE_DIR = \"../../dat/glove\"\n",
    "    embeddings_index = {}\n",
    "    f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    print('Total %s word vectors.' % len(embeddings_index))    \n",
    "    embedding_matrix = np.random.random((len(word_index) + 1, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            #print(i, ' ', embedding_vector.shape)\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fc4d3fe9310>]], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc4d3fe94d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#SCALE target variable\n",
    "train[\"target\"] = np.log(train.price+1)\n",
    "target_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train[\"target\"] = target_scaler.fit_transform(train.target.reshape(-1,1))\n",
    "pd.DataFrame(train.target).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1467709, 11)\n",
      "(14826, 11)\n"
     ]
    }
   ],
   "source": [
    "#EXTRACT DEVELOPTMENT TEST\n",
    "dtrain, dvalid = train_test_split(train, random_state=123, train_size=0.99)\n",
    "print(dtrain.shape)\n",
    "print(dvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#KERAS DATA DEFINITION\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def get_keras_data(dataset):\n",
    "    seq_item_description_data = np.reshape(list(dataset.seq_item_description), [len(dataset.seq_item_description), MAX_SENTS,MAX_SENT_LENGTH])\n",
    "    X = {\n",
    "        'name': pad_sequences(dataset.seq_name, maxlen=MAX_NAME_SEQ)\n",
    "        ,'item_desc': seq_item_description_data\n",
    "        ,'brand_name': np.array(dataset.brand_name)\n",
    "        ,'category_name': np.array(dataset.category_name)\n",
    "        ,'item_condition': np.array(dataset.item_condition_id)\n",
    "        ,'num_vars': np.array(dataset[[\"shipping\"]])\n",
    "    }\n",
    "    return X\n",
    "\n",
    "X_train = get_keras_data(dtrain)\n",
    "X_valid = get_keras_data(dvalid)\n",
    "X_test = get_keras_data(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 7396 word vectors.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "item_desc (InputLayer)          (None, 5, 25)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 5, 20)        25931812    item_desc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "brand_name (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "category_name (InputLayer)      (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_condition (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 5, 16)        1392        time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "name (InputLayer)               (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 10)        52900       brand_name[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 10)        13110       category_name[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 5)         30          item_condition[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 5, 20)        340         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 10, 50)       12959950    name[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 10)           0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 10)           0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 5)            0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "att_layer_2 (AttLayer)          (None, 20)           20          time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "gru_3 (GRU)                     (None, 8)            1416        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 53)           0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 att_layer_2[0][0]                \n",
      "                                                                 gru_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          6912        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           8256        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            65          dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 38,976,203\n",
      "Trainable params: 38,976,203\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfrom keras.utils.vis_utils import plot_model\\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KERAS MODEL DEFINITION\n",
    "from keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, GRU, Embedding, Flatten, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras import backend as K\n",
    "\n",
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave]\n",
    "\n",
    "def rmsle_cust(y_true, y_pred):\n",
    "    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n",
    "    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n",
    "    return K.sqrt(K.mean(K.square(first_log - second_log), axis=-1))\n",
    "\n",
    "def get_HATT_representation(item_desc_input_layer):\n",
    "    \n",
    "    # building Hierachical Attention network\n",
    "    EMBEDDING_DIM = 100\n",
    "    # Pre-trained Embeddings\n",
    "    embedding_matrix = get_embeddings_matrix(embedding_dim=EMBEDDING_DIM)\n",
    "    \n",
    "    embedding_layer = Embedding(len(word_index) + 1,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=MAX_SENT_LENGTH,\n",
    "                                trainable=True)\n",
    "    \n",
    "    # Attention\n",
    "    from keras.engine.topology import Layer\n",
    "    from keras import initializers\n",
    "    from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "    class AttLayer(Layer):\n",
    "        def __init__(self, **kwargs):\n",
    "            self.init = initializers.VarianceScaling(scale=1.0, mode='fan_in', distribution='normal', seed=None)\n",
    "            super(AttLayer, self).__init__(**kwargs)\n",
    "\n",
    "        def build(self, input_shape):\n",
    "            assert len(input_shape)==3\n",
    "            self.W = K.variable((self.init((input_shape[-1],1))))\n",
    "            self.trainable_weights = [self.W]\n",
    "            super(AttLayer, self).build(input_shape)  # be sure you call this somewhere!\n",
    "\n",
    "        def call(self, x, mask=None):\n",
    "            eij = K.tanh(K.dot(x, self.W))\n",
    "\n",
    "            ai = K.exp(eij)\n",
    "            weights = ai/tf.expand_dims(K.sum(ai, axis=1), 1)\n",
    "\n",
    "            weighted_input = x*weights\n",
    "            return tf.reduce_sum(weighted_input, axis=1)\n",
    "\n",
    "        def compute_output_shape(self, input_shape):\n",
    "            return (input_shape[0], input_shape[-1])\n",
    "\n",
    "\n",
    "    \n",
    "    # HATT model\n",
    "    sentence_input = Input(shape=(MAX_SENT_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sentence_input)\n",
    "\n",
    "    l_lstm = Bidirectional(GRU(16, return_sequences=True))(embedded_sequences)\n",
    "    l_dense = TimeDistributed(Dense(20))(l_lstm)\n",
    "    l_att = AttLayer()(l_dense)\n",
    "    sentEncoder = Model(sentence_input, l_att)\n",
    "    \n",
    "    '''\n",
    "    l_lstm = Bidirectional(LSTM(100))(embedded_sequences)\n",
    "    sentEncoder = Model(sentence_input, l_lstm)\n",
    "    '''\n",
    "\n",
    "    #review_input = Input(shape=(MAX_SENTS,MAX_SENT_LENGTH), dtype='int32')\n",
    "    review_encoder = TimeDistributed(sentEncoder)(item_desc_input_layer)\n",
    "\n",
    "    '''\n",
    "    l_lstm_sent = Bidirectional(LSTM(100))(review_encoder)\n",
    "    '''\n",
    "\n",
    "    \n",
    "    l_lstm_sent = Bidirectional(GRU(8, return_sequences=True))(review_encoder)\n",
    "    l_dense_sent = TimeDistributed(Dense(20))(l_lstm_sent)\n",
    "    l_att_sent = AttLayer()(l_dense_sent)\n",
    "    \n",
    "    return l_att_sent\n",
    "    #return l_lstm_sent\n",
    "\n",
    "def get_model():\n",
    "    #params\n",
    "    dr_r = 0.1\n",
    "    \n",
    "    #Inputs\n",
    "    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n",
    "    \n",
    "    item_desc = Input(shape=[MAX_SENTS, MAX_SENT_LENGTH], name=\"item_desc\")\n",
    "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
    "    category_name = Input(shape=[1], name=\"category_name\")\n",
    "    item_condition = Input(shape=[1], name=\"item_condition\")\n",
    "    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n",
    "    \n",
    "    #Embeddings layers\n",
    "    emb_name = Embedding(MAX_TEXT, 50)(name)\n",
    "    #emb_item_desc = Embedding(MAX_TEXT, 50)(item_desc)\n",
    "    emb_brand_name = Embedding(MAX_BRAND, 10)(brand_name)\n",
    "    emb_category_name = Embedding(MAX_CATEGORY, 10)(category_name)\n",
    "    emb_item_condition = Embedding(MAX_CONDITION, 5)(item_condition)\n",
    "    \n",
    "    #rnn layer\n",
    "    HATT_layer = get_HATT_representation(item_desc)\n",
    "    rnn_layer2 = GRU(8) (emb_name)\n",
    "    \n",
    "    #main layer\n",
    "    \n",
    "    main_l = concatenate([\n",
    "        Flatten() (emb_brand_name)\n",
    "        , Flatten() (emb_category_name)\n",
    "        , Flatten() (emb_item_condition)\n",
    "        , HATT_layer\n",
    "        , rnn_layer2\n",
    "        #, num_vars\n",
    "    ])\n",
    "    \n",
    "    #main_l = num_vars\n",
    "    main_l = Dropout(dr_r) (Dense(128) (main_l))\n",
    "    main_l = Dropout(dr_r) (Dense(64) (main_l))\n",
    "    \n",
    "    #output\n",
    "    output = Dense(1, activation=\"linear\") (main_l)\n",
    "    \n",
    "    #model\n",
    "    import keras.optimizers\n",
    "    lr = 0.01\n",
    "    opt = keras.optimizers.adagrad(lr)\n",
    "    model = Model([name, item_desc, brand_name\n",
    "                   , category_name, item_condition, num_vars], output)\n",
    "    model.compile(loss=\"mse\", optimizer=opt, metrics=[\"mae\", rmsle_cust])\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "model = get_model()\n",
    "model.summary()\n",
    "'''\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 7396 word vectors.\n",
      "Train on 1467709 samples, validate on 14826 samples\n",
      "Epoch 1/5\n",
      "1467709/1467709 [==============================] - 47s 32us/step - loss: 0.3240 - mean_absolute_error: 0.2572 - rmsle_cust: 0.0358 - val_loss: 0.0275 - val_mean_absolute_error: 0.1285 - val_rmsle_cust: 0.0159\n",
      "Epoch 2/5\n",
      "1467709/1467709 [==============================] - 44s 30us/step - loss: 0.0302 - mean_absolute_error: 0.1347 - rmsle_cust: 0.0161 - val_loss: 0.0214 - val_mean_absolute_error: 0.1120 - val_rmsle_cust: 0.0142\n",
      "Epoch 3/5\n",
      "1467709/1467709 [==============================] - 44s 30us/step - loss: 0.0247 - mean_absolute_error: 0.1212 - rmsle_cust: 0.0151 - val_loss: 0.0202 - val_mean_absolute_error: 0.1083 - val_rmsle_cust: 0.0138\n",
      "Epoch 4/5\n",
      "1467709/1467709 [==============================] - 44s 30us/step - loss: 0.0222 - mean_absolute_error: 0.1145 - rmsle_cust: 0.0144 - val_loss: 0.0195 - val_mean_absolute_error: 0.1063 - val_rmsle_cust: 0.0136\n",
      "Epoch 5/5\n",
      "1467709/1467709 [==============================] - 44s 30us/step - loss: 0.0208 - mean_absolute_error: 0.1102 - rmsle_cust: 0.0140 - val_loss: 0.0191 - val_mean_absolute_error: 0.1050 - val_rmsle_cust: 0.0135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc4cff054d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FITTING THE MODEL\n",
    "BATCH_SIZE = 20000\n",
    "epochs = 5\n",
    "\n",
    "model = get_model()\n",
    "model.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n",
    "          , validation_data=(X_valid, dvalid.target)\n",
    "          , verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFold (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    assert len(y) == len(y_pred)\n",
    "    to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n",
    "    return (sum(to_sum) * (1.0/len(y))) ** 0.5\n",
    "#Source: https://www.kaggle.com/marknagelberg/rmsle-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSLE error on dev test: 0.539568807151\n"
     ]
    }
   ],
   "source": [
    "#EVLUEATE THE MODEL ON DEV TEST: What is it doing?\n",
    "val_preds = model.predict(X_valid)\n",
    "val_preds = target_scaler.inverse_transform(val_preds)\n",
    "val_preds = np.exp(val_preds)+1\n",
    "\n",
    "#mean_absolute_error, mean_squared_log_error\n",
    "y_true = np.array(dvalid.price.values)\n",
    "y_pred = val_preds[:,0]\n",
    "v_rmsle = rmsle(y_true, y_pred)\n",
    "print(\" RMSLE error on dev test: \"+str(v_rmsle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#CREATE PREDICTIONS\n",
    "preds = model.predict(X_test, batch_size=BATCH_SIZE)\n",
    "preds = target_scaler.inverse_transform(preds)\n",
    "preds = np.exp(preds)-1\n",
    "\n",
    "submission = test[[\"test_id\"]]\n",
    "submission[\"price\"] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc4e88bcb90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEACAYAAAB27puMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc4e0037e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission.to_csv(\"./myNNsubmission.csv\", index=False)\n",
    "submission.price.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "\n",
    "https://www.kaggle.com/knowledgegrappler/a-simple-nn-solution-with-keras-0-48611-pl"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
